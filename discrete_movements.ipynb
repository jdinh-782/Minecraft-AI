{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "# import MalmoPython\n",
    "import malmo.MalmoPython as MalmoPython\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import errno\n",
    "import logging\n",
    "import pickle\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "from collections import defaultdict, deque\n",
    "from timeit import default_timer as timer\n",
    "from pprint import pprint\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    # Workaround for https://github.com/PythonCharmers/python-future/issues/262\n",
    "    import Tkinter as tk\n",
    "else:\n",
    "    import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMaze(fname=0):\n",
    "    random.seed()\n",
    "\n",
    "    water_xml = \"\"\n",
    "    logs_xml = \"\\n\"\n",
    "    z_used = []\n",
    "    for i in range(4):\n",
    "        x1 = random.randint(0, 2)        \n",
    "        x2 = x1 + random.randint(1, 2)\n",
    "        \n",
    "        z = -5\n",
    "        while True:\n",
    "            z = random.randint(-5, 12)\n",
    "            if z not in z_used:\n",
    "                z_used.append(z)\n",
    "                break\n",
    "        \n",
    "        water_xml = water_xml + '''\n",
    "                <DrawCuboid x1=\"{x1}\"   y1=\"45\"  z1=\"{z1}\"   x2=\"{x2}\"  y2=\"45\"  z2=\"{z2}\" type=\"water\"/>'''.format(x1=x1, x2=x2, z1=z, z2=z)\n",
    "        \n",
    "        x1 = random.randint(0, 2)\n",
    "        x2 = x1 + random.randint(0, 1)\n",
    "        \n",
    "        z = -5\n",
    "        while True:\n",
    "            z = random.randint(-5, 12)\n",
    "            if z not in z_used:\n",
    "                z_used.append(z)\n",
    "                break\n",
    "                \n",
    "        logs_xml = logs_xml + '''\n",
    "                <DrawCuboid x1=\"{x1}\"  y1=\"46\"  z1=\"{z1}\"   x2=\"{x2}\"  y2=\"47\"  z2=\"{z2}\" type=\"log\" />'''.format(x1=x1, x2=x2, z1=z, z2=z)\n",
    "                \n",
    "#     print(\"water_xml: \", water_xml)\n",
    "#     print(\"logs_xml: \", logs_xml)\n",
    "\n",
    "    \n",
    "    xml_str = '''<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\" ?>\n",
    "        <Mission xmlns=\"http://ProjectMalmo.microsoft.com\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
    "\n",
    "          <About>\n",
    "            <Summary>Racing track simulation with reinforcement learning agent!</Summary>\n",
    "          </About>\n",
    "\n",
    "          <ServerSection>\n",
    "            <ServerInitialConditions>\n",
    "                <Time><StartTime>1</StartTime></Time>\n",
    "            </ServerInitialConditions>\n",
    "            <ServerHandlers>\n",
    "              <FlatWorldGenerator generatorString=\"3;7,2;1;\"/>\n",
    "              <DrawingDecorator>\n",
    "                <!-- coordinates for cuboid are inclusive -->\n",
    "                <!-- limits of our arena -->\n",
    "                <DrawCuboid x1=\"-4\"  y1=\"46\"  z1=\"-13\"  x2=\"9\"  y2=\"50\"  z2=\"13\" type=\"air\" />           \n",
    "                \n",
    "                <!-- lava floor -->\n",
    "                <DrawCuboid x1=\"-4\"  y1=\"45\"  z1=\"-13\"  x2=\"9\"  y2=\"45\"  z2=\"13\" type=\"lava\" />        \n",
    "                \n",
    "                <!-- floor of the arena -->\n",
    "                <DrawCuboid x1=\"-1\"  y1=\"45\"  z1=\"-8\"   x2=\"5\"  y2=\"45\"  z2=\"13\" type=\"packed_ice\" />\n",
    "                \n",
    "                <!-- water area -->''' + water_xml + logs_xml + '''         \n",
    "                \n",
    "                <!-- the starting marker -->\n",
    "                <DrawBlock x=\"2\"  y=\"45\" z=\"-8\" type=\"cobblestone\" />                  \n",
    "                \n",
    "                <!-- the destination markers -->\n",
    "                <DrawBlock x=\"5\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                \n",
    "                <DrawBlock x=\"4\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                \n",
    "                <DrawBlock x=\"3\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                                 \n",
    "                <DrawBlock x=\"2\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                                  \n",
    "                <DrawBlock x=\"1\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                                  \n",
    "                <DrawBlock x=\"0\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                                  \n",
    "                <DrawBlock x=\"-1\"  y=\"45\" z=\"13\" type=\"diamond_block\" />                                 \n",
    "              </DrawingDecorator>\n",
    "              <ServerQuitFromTimeUp timeLimitMs=\"15000\"/>\n",
    "              <ServerQuitWhenAnyAgentFinishes/>\n",
    "            </ServerHandlers>\n",
    "          </ServerSection>\n",
    "\n",
    "          <AgentSection mode=\"Survival\">\n",
    "            <Name>Agent</Name>\n",
    "            <AgentStart>\n",
    "              <Placement x=\"2.5\" y=\"46.0\" z=\"-7.5\" pitch=\"30\" yaw=\"0\"/>\n",
    "            </AgentStart>\n",
    "            <AgentHandlers>\n",
    "              <DiscreteMovementCommands/>\n",
    "              <ObservationFromFullStats/>\n",
    "              <RewardForTouchingBlockType>\n",
    "                <Block reward=\"250.0\" type=\"diamond_block\" behaviour=\"onceOnly\"/>\n",
    "                <Block reward=\"-100.0\" type=\"lava\" behaviour=\"onceOnly\"/>\n",
    "                <Block reward=\"-50.0\" type=\"water\" behaviour=\"onceOnly\"/>\n",
    "                <Block reward=\"-25.0\" type=\"log\" behaviour=\"constant\"/>\n",
    "                <Block reward=\"2\" type=\"packed_ice\" behaviour=\"constant\"/>\n",
    "              </RewardForTouchingBlockType>\n",
    "              <RewardForSendingCommand reward=\"-1\" />\n",
    "              <AgentQuitFromTouchingBlockType>\n",
    "                  <Block type=\"lava\" description=\"fail\"/>\n",
    "                  <Block type=\"water\" description=\"fail\"/>\n",
    "                  <Block type=\"diamond_block\" description=\"complete\"/>\n",
    "              </AgentQuitFromTouchingBlockType>\n",
    "            </AgentHandlers>\n",
    "          </AgentSection>\n",
    "\n",
    "        </Mission>\n",
    "        '''\n",
    "    \n",
    "    with open(\"xmls/discrete/world_{}.xml\".format(fname), \"w\") as f:\n",
    "        f.write(xml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file  0\n",
      "saving file  0\n",
      "creating file  1\n",
      "saving file  1\n",
      "creating file  2\n",
      "saving file  2\n",
      "creating file  3\n",
      "saving file  3\n",
      "creating file  4\n",
      "saving file  4\n",
      "creating file  5\n",
      "saving file  5\n",
      "creating file  6\n",
      "saving file  6\n",
      "creating file  7\n",
      "saving file  7\n",
      "creating file  8\n",
      "saving file  8\n",
      "creating file  9\n",
      "saving file  9\n",
      "creating file  10\n",
      "saving file  10\n",
      "creating file  11\n",
      "saving file  11\n",
      "creating file  12\n",
      "saving file  12\n",
      "creating file  13\n",
      "saving file  13\n",
      "creating file  14\n",
      "saving file  14\n",
      "creating file  15\n",
      "saving file  15\n",
      "creating file  16\n",
      "saving file  16\n",
      "creating file  17\n",
      "saving file  17\n",
      "creating file  18\n",
      "saving file  18\n",
      "creating file  19\n",
      "saving file  19\n"
     ]
    }
   ],
   "source": [
    "num_files = 20\n",
    "for i in range(num_files):\n",
    "    print(\"creating file \", i)\n",
    "    saveMaze(i)\n",
    "    print(\"saving file \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Racer Agent (DiscreteMovementCommands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards_map =  {'diamond_block': 250, 'packed_ice': 2, 'log': -25, 'water': -50, 'lava': -100}\n",
    "actions_space = [\"movenorth 1\", \"movesouth 1\", \"movewest 1\", \"moveeast 1\", \"jumpsouth 1\", \"jumpsouth 0\"] \n",
    "# REMINDER: VALUE OF EACH ACTION IS THE SPEED, NOT NUMBER OF TIMES\n",
    "# move  1    full speed ahead\n",
    "# move -1    full speed backwards\n",
    "# strafe 1   moves right at full speed\n",
    "# strafe -1  moves left at full speed\n",
    "# turn 1     turns full speed right\n",
    "# turn -1    turns full speed left\n",
    "# jump 1/0   starts/stops jumping\n",
    "\n",
    "\n",
    "class Racer(object):\n",
    "    # initializing the parameters for the agent\n",
    "    def __init__(self, epsilon=0.01, n=1):\n",
    "        \"\"\"Tabular Q-learning agent for discrete state/action spaces.\"\"\"\n",
    "        \n",
    "        self.epsilon = epsilon  # chance of taking a random action instead of the best\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if False: # True if you want to see more information\n",
    "            self.logger.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "        self.logger.handlers = []\n",
    "        self.logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "        \n",
    "        self.actions = actions_space\n",
    "        self.q_table = {}\n",
    "        self.canvas = None\n",
    "        self.root = None\n",
    "        \n",
    "    def updateQTable( self, reward, current_state ):\n",
    "        \"\"\"Change q_table to reflect what we have learnt.\"\"\"\n",
    "        \n",
    "        # retrieve the old action value from the Q-table (indexed by the previous state and the previous action)\n",
    "        old_q = self.q_table[self.prev_s][self.prev_a]\n",
    "        \n",
    "        # TODO: what should the new action value be?\n",
    "        new_q = old_q\n",
    "        \n",
    "        # assign the new action value to the Q-table\n",
    "        self.q_table[self.prev_s][self.prev_a] = new_q\n",
    "        \n",
    "    def updateQTableFromTerminatingState( self, reward ):\n",
    "        \"\"\"Change q_table to reflect what we have learnt, after reaching a terminal state.\"\"\"\n",
    "        \n",
    "        # retrieve the old action value from the Q-table (indexed by the previous state and the previous action)\n",
    "        old_q = self.q_table[self.prev_s][self.prev_a]\n",
    "        \n",
    "        # TODO: what should the new action value be?\n",
    "        new_q = old_q\n",
    "        \n",
    "        # assign the new action value to the Q-table\n",
    "        self.q_table[self.prev_s][self.prev_a] = new_q\n",
    "        \n",
    "    def act(self, world_state, agent_host, current_r ):\n",
    "        \"\"\"take 1 action in response to the current world state\"\"\"\n",
    "        \n",
    "        obs_text = world_state.observations[-1].text\n",
    "        obs = json.loads(obs_text) # most recent observation\n",
    "        self.logger.debug(obs)\n",
    "\n",
    "        if not u'XPos' in obs or not u'ZPos' in obs:\n",
    "            self.logger.error(\"Incomplete observation received: %s\" % obs_text)\n",
    "            return 0\n",
    "        current_s = \"%d:%d\" % (int(obs[u'XPos']), int(obs[u'ZPos']))\n",
    "        self.logger.debug(\"State: %s (x = %.2f, z = %.2f)\" % (current_s, float(obs[u'XPos']), float(obs[u'ZPos'])))\n",
    "        print(\"State: %s (x = %.2f, z = %.2f)\" % (current_s, float(obs[u'XPos']), float(obs[u'ZPos'])))\n",
    "        \n",
    "        if current_s not in self.q_table:\n",
    "            self.q_table[current_s] = ([0] * len(self.actions))\n",
    "\n",
    "        # update Q values\n",
    "        if self.prev_s is not None and self.prev_a is not None:\n",
    "            self.updateQTable( current_r, current_s )\n",
    "\n",
    "        self.drawQ( curr_x = int(obs[u'XPos']), curr_y = int(obs[u'ZPos']) )\n",
    "\n",
    "        # select the next action\n",
    "        rnd = random.random()\n",
    "        if rnd < self.epsilon:\n",
    "            a = random.randint(0, len(self.actions) - 1)\n",
    "            self.logger.info(\"Random action: %s\" % self.actions[a])\n",
    "        else:\n",
    "            m = max(self.q_table[current_s])\n",
    "            self.logger.debug(\"Current values: %s\" % \",\".join(str(x) for x in self.q_table[current_s]))\n",
    "            l = list()\n",
    "            for x in range(0, len(self.actions)):\n",
    "                if self.q_table[current_s][x] == m:\n",
    "                    l.append(x)\n",
    "            y = random.randint(0, len(l)-1)\n",
    "            a = l[y]\n",
    "       \n",
    "            self.logger.info(\"Taking q action: %s with current reward: %s\" % (self.actions[a], current_r))\n",
    "\n",
    "        # try to send the selected action, only update prev_s if this succeeds\n",
    "        try:\n",
    "            agent_host.sendCommand(self.actions[a])\n",
    "            \n",
    "            if self.actions[a] == \"jumpsouth 1\":\n",
    "                agent_host.sendCommand(\"movesouth 1\")\n",
    "            \n",
    "            self.prev_s = current_s\n",
    "            self.prev_a = a\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            self.logger.error(\"Failed to send command: %s\" % e)\n",
    "\n",
    "        return current_r\n",
    "    \n",
    "    def clear_actions(self):\n",
    "        \"\"\"Resets the actions taken in case of a new attempt to fetch.\"\"\"\n",
    "        self.q_table = {}\n",
    "    \n",
    "    def run(self, agent_host):\n",
    "        \"\"\"run the agent on the world\"\"\"\n",
    "\n",
    "        total_reward = 0\n",
    "        current_r = 0\n",
    "        \n",
    "        self.prev_s = None\n",
    "        self.prev_a = None\n",
    "        \n",
    "        is_first_action = True\n",
    "        \n",
    "        # main loop:\n",
    "        world_state = agent_host.getWorldState()\n",
    "        while world_state.is_mission_running:\n",
    "\n",
    "            current_r = 0\n",
    "            \n",
    "            if is_first_action:\n",
    "                # wait until have received a valid observation\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        total_reward += self.act(world_state, agent_host, current_r)\n",
    "                        break\n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "                is_first_action = False\n",
    "            else:\n",
    "                # wait for non-zero reward\n",
    "                while world_state.is_mission_running and current_r == 0:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                # allow time to stabilise after action\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        total_reward += self.act(world_state, agent_host, current_r)\n",
    "                        break\n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "\n",
    "        # process final reward\n",
    "        self.logger.debug(\"Final reward: %d\" % current_r)\n",
    "        total_reward += current_r\n",
    "\n",
    "        # update Q values\n",
    "        if self.prev_s is not None and self.prev_a is not None:\n",
    "            self.updateQTableFromTerminatingState( current_r )\n",
    "            \n",
    "        self.drawQ()\n",
    "    \n",
    "        return total_reward\n",
    "    \n",
    "    # modify this to for world dimensions on Q-table\n",
    "    def drawQ( self, curr_x=None, curr_y=None ):\n",
    "        scale = 40\n",
    "        world_x = 6\n",
    "        world_y = 14\n",
    "        if self.canvas is None or self.root is None:\n",
    "            self.root = tk.Tk()\n",
    "            self.root.wm_title(\"Q-table\")\n",
    "            self.canvas = tk.Canvas(self.root, width=world_x*scale, height=world_y*scale, borderwidth=0, highlightthickness=0, bg=\"black\")\n",
    "            self.canvas.grid()\n",
    "            self.root.update()\n",
    "        self.canvas.delete(\"all\")\n",
    "        action_inset = 0.1\n",
    "        action_radius = 0.1\n",
    "        curr_radius = 0.2\n",
    "        action_positions = [ ( 0.5, action_inset ), ( 0.5, 1-action_inset ), ( action_inset, 0.5 ), ( 1-action_inset, 0.5 ) ]\n",
    "        # (NSWE to match action order)\n",
    "        min_value = -20\n",
    "        max_value = 20\n",
    "        for x in range(world_x):\n",
    "            for y in range(world_y):\n",
    "                s = \"%d:%d\" % (x,y)\n",
    "                self.canvas.create_rectangle( x*scale, y*scale, (x+1)*scale, (y+1)*scale, outline=\"#fff\", fill=\"#000\")\n",
    "                for action in range(4):\n",
    "                    if not s in self.q_table:\n",
    "                        continue\n",
    "                    value = self.q_table[s][action]\n",
    "                    color = int( 255 * ( value - min_value ) / ( max_value - min_value )) # map value to 0-255\n",
    "                    color = max( min( color, 255 ), 0 ) # ensure within [0,255]\n",
    "                    color_string = '#%02x%02x%02x' % (255-color, color, 0)\n",
    "                    self.canvas.create_oval( (x + action_positions[action][0] - action_radius ) *scale,\n",
    "                                             (y + action_positions[action][1] - action_radius ) *scale,\n",
    "                                             (x + action_positions[action][0] + action_radius ) *scale,\n",
    "                                             (y + action_positions[action][1] + action_radius ) *scale, \n",
    "                                             outline=color_string, fill=color_string )\n",
    "        if curr_x is not None and curr_y is not None:\n",
    "            self.canvas.create_oval( (curr_x + 0.5 - curr_radius ) * scale, \n",
    "                                     (curr_y + 0.5 - curr_radius ) * scale, \n",
    "                                     (curr_x + 0.5 + curr_radius ) * scale, \n",
    "                                     (curr_y + 0.5 + curr_radius ) * scale, \n",
    "                                     outline=\"#fff\", fill=\"#fff\" )\n",
    "        self.root.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Caught std::exception: unrecognised option '-f'\n",
      "\n",
      "Malmo version: 0.36.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n",
      "Loading mission from xmls/discrete/world_18.xml\n",
      "n = 10\n",
      "\n",
      "Waiting for the mission to start on trial 1\n",
      "Mission running...\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 0\n",
      "State: 2:-6 (x = 2.50, z = -6.50)\n",
      "Taking q action: movenorth 1 with current reward: -1.0\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Taking q action: movewest 1 with current reward: -1.0\n",
      "State: 1:-7 (x = 1.50, z = -7.50)\n",
      "Taking q action: movesouth 1 with current reward: 5.0\n",
      "State: 1:-6 (x = 1.50, z = -6.50)\n",
      "Taking q action: movewest 1 with current reward: 7.0\n",
      "State: 0:-6 (x = 0.50, z = -6.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 5.0\n",
      "State: 0:-4 (x = 0.50, z = -4.50)\n",
      "Taking q action: movesouth 1 with current reward: 6.0\n",
      "State: 0:-3 (x = 0.50, z = -3.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 7.0\n",
      "State: 0:-2 (x = 0.50, z = -2.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 1.0\n",
      "State: 0:0 (x = 0.50, z = -0.50)\n",
      "Taking q action: movesouth 1 with current reward: 4.0\n",
      "State: 0:0 (x = 0.50, z = 0.50)\n",
      "Taking q action: movenorth 1 with current reward: 9.0\n",
      "State: 0:0 (x = 0.50, z = -0.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 0:1 (x = 0.50, z = 1.50)\n",
      "Taking q action: movesouth 1 with current reward: 0.0\n",
      "State: 0:2 (x = 0.50, z = 2.50)\n",
      "Taking q action: movenorth 1 with current reward: 7.0\n",
      "State: 0:1 (x = 0.50, z = 1.50)\n",
      "Taking q action: movenorth 1 with current reward: 7.0\n",
      "State: 0:0 (x = 0.50, z = 0.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 0:2 (x = 0.50, z = 2.50)\n",
      "Taking q action: moveeast 1 with current reward: 6.0\n",
      "State: 1:2 (x = 1.50, z = 2.50)\n",
      "Taking q action: moveeast 1 with current reward: 7.0\n",
      "State: 2:2 (x = 2.50, z = 2.50)\n",
      "Taking q action: moveeast 1 with current reward: 7.0\n",
      "State: 3:2 (x = 3.50, z = 2.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 7.0\n",
      "State: 3:3 (x = 3.50, z = 3.50)\n",
      "Taking q action: moveeast 1 with current reward: 1.0\n",
      "State: 4:3 (x = 4.50, z = 3.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 4:5 (x = 4.50, z = 5.50)\n",
      "Taking q action: movewest 1 with current reward: 6.0\n",
      "State: 3:5 (x = 3.50, z = 5.50)\n",
      "Taking q action: movenorth 1 with current reward: 7.0\n",
      "State: 3:4 (x = 3.50, z = 4.50)\n",
      "Taking q action: moveeast 1 with current reward: 7.0\n",
      "State: 4:4 (x = 4.50, z = 4.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 7.0\n",
      "State: 4:5 (x = 4.50, z = 5.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 1.0\n",
      "State: 4:6 (x = 4.50, z = 6.50)\n",
      "Taking q action: movenorth 1 with current reward: 1.0\n",
      "State: 4:5 (x = 4.50, z = 5.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 4:7 (x = 4.50, z = 7.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 6.0\n",
      "State: 4:9 (x = 4.50, z = 9.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 6.0\n",
      "State: 4:10 (x = 4.50, z = 10.50)\n",
      "Taking q action: movesouth 1 with current reward: 1.0\n",
      "State: 4:11 (x = 4.50, z = 11.50)\n",
      "Taking q action: movenorth 1 with current reward: 7.0\n",
      "State: 4:10 (x = 4.50, z = 10.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 4:12 (x = 4.50, z = 12.50)\n",
      "Taking q action: movenorth 1 with current reward: 6.0\n",
      "State: 4:11 (x = 4.50, z = 11.50)\n",
      "Taking q action: movesouth 1 with current reward: 7.0\n",
      "State: 4:12 (x = 4.50, z = 12.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 9.0\n",
      "Cumulative reward: 190\n",
      "\n",
      "Waiting for the mission to start on trial 2\n",
      "Mission running...\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Taking q action: movenorth 1 with current reward: 0\n",
      "Cumulative reward: -101\n",
      "\n",
      "Waiting for the mission to start on trial 3\n",
      "Mission running...\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Taking q action: moveeast 1 with current reward: 0\n",
      "State: 3:-7 (x = 3.50, z = -7.50)\n",
      "Taking q action: movesouth 1 with current reward: 7.0\n",
      "State: 3:-6 (x = 3.50, z = -6.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: movesouth 1 with current reward: -46.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: moveeast 1 with current reward: -39.0\n",
      "State: 4:-5 (x = 4.50, z = -5.50)\n",
      "Taking q action: movenorth 1 with current reward: 7.0\n",
      "State: 4:-6 (x = 4.50, z = -6.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 7.0\n",
      "State: 4:-4 (x = 4.50, z = -4.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 4.0\n",
      "State: 4:-3 (x = 4.50, z = -3.50)\n",
      "Taking q action: movewest 1 with current reward: 1.0\n",
      "State: 3:-3 (x = 3.50, z = -3.50)\n",
      "Random action: movewest 1\n",
      "State: 2:-3 (x = 2.50, z = -3.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 9.0\n",
      "State: 2:-1 (x = 2.50, z = -1.50)\n",
      "Taking q action: movewest 1 with current reward: 0.0\n",
      "State: 1:-1 (x = 1.50, z = -1.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 9.0\n",
      "State: 1:0 (x = 1.50, z = 0.50)\n",
      "Taking q action: movenorth 1 with current reward: 6.0\n",
      "State: 1:0 (x = 1.50, z = -0.50)\n",
      "Taking q action: moveeast 1 with current reward: 7.0\n",
      "Cumulative reward: -63\n",
      "\n",
      "Waiting for the mission to start on trial 4\n",
      "Mission running...\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Random action: movenorth 1\n",
      "Cumulative reward: -101\n",
      "\n",
      "Waiting for the mission to start on trial 5\n",
      "Mission running...\n",
      "State: 2:-7 (x = 2.50, z = -7.50)\n",
      "Taking q action: jumpsouth 1 with current reward: 0\n",
      "State: 2:-5 (x = 2.50, z = -5.50)\n",
      "Taking q action: moveeast 1 with current reward: 0.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: jumpsouth 0 with current reward: 9.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: jumpsouth 1 with current reward: -47.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: jumpsouth 0 with current reward: -96.0\n",
      "State: 3:-5 (x = 3.50, z = -5.50)\n",
      "Taking q action: movewest 1 with current reward: -45.0\n",
      "State: 2:-5 (x = 2.50, z = -5.50)\n",
      "Taking q action: movewest 1 with current reward: 7.0\n",
      "State: 1:-5 (x = 1.50, z = -5.50)\n",
      "Taking q action: movesouth 1 with current reward: 9.0\n",
      "State: 1:-4 (x = 1.50, z = -4.50)\n",
      "Taking q action: movesouth 1 with current reward: 5.0\n",
      "State: 1:-3 (x = 1.50, z = -3.50)\n",
      "Taking q action: movesouth 1 with current reward: 7.0\n",
      "Cumulative reward: -198\n",
      "\n",
      "\n",
      "Mission ended.\n",
      "Cumulative rewards for all 5 runs:\n",
      "[190.0, -101.0, -63.0, -101.0, -198.0]\n"
     ]
    }
   ],
   "source": [
    "if sys.version_info[0] == 2:\n",
    "    sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)  # flush print output immediately\n",
    "else:\n",
    "    import functools\n",
    "    print = functools.partial(print, flush=True)\n",
    "    \n",
    "\n",
    "my_client_pool = MalmoPython.ClientPool()\n",
    "my_client_pool.add(MalmoPython.ClientInfo(\"127.0.0.1\", 10000))\n",
    "\n",
    "\n",
    "# Create default Malmo objects:\n",
    "agent_host = MalmoPython.AgentHost()\n",
    "try:\n",
    "    agent_host.parse( sys.argv )\n",
    "except RuntimeError as e:\n",
    "    print('ERROR:',e)\n",
    "    print(agent_host.getUsage())\n",
    "    exit(1)\n",
    "#     sys.exit()\n",
    "if agent_host.receivedArgument(\"help\"):\n",
    "    print(agent_host.getUsage())\n",
    "    exit(0)\n",
    "#     sys.exit()\n",
    "\n",
    "\n",
    "# load in world map\n",
    "world_num = random.randint(0, 19)\n",
    "# mission_file = \"xmls/discrete/discreteTestMap.txt\"  # test map\n",
    "mission_file = 'xmls/discrete/world_{world_num}.xml'.format(world_num=world_num)\n",
    "with open(mission_file, 'r') as f:\n",
    "    print(\"Loading mission from %s\" % mission_file)\n",
    "    missionXML = f.read()\n",
    "\n",
    "    \n",
    "# initiate the Racer object\n",
    "num_reps = 5\n",
    "n = 10\n",
    "racer = Racer(n=n)\n",
    "print(\"n =\", n)\n",
    "racer.clear_actions()\n",
    "\n",
    "\n",
    "cumulative_rewards = []\n",
    "for iRepeat in range(num_reps):\n",
    "    my_mission = MalmoPython.MissionSpec(missionXML, True)\n",
    "    my_mission_record = MalmoPython.MissionRecordSpec()  # Records nothing by default\n",
    "    my_mission.requestVideo(1260, 960)\n",
    "    my_mission.setViewpoint(0)\n",
    "\n",
    "    # Attempt to start a mission:\n",
    "    max_retries = 3\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            agent_host.startMission( my_mission, my_client_pool, my_mission_record, 0, \"Racer\" )\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            if retry == max_retries - 1:\n",
    "                print(\"Error starting mission:\",e)\n",
    "                exit(1)\n",
    "                # sys.exit()\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "\n",
    "    # Loop until mission starts:\n",
    "    print(\"\\nWaiting for the mission to start on trial\", iRepeat+1)\n",
    "    world_state = agent_host.getWorldState()\n",
    "    \n",
    "    while not world_state.has_mission_begun:\n",
    "        time.sleep(0.1)\n",
    "        world_state = agent_host.getWorldState()\n",
    "        for error in world_state.errors:\n",
    "            print(\"Error:\",error.text)\n",
    "    \n",
    "    print(\"Mission running...\")\n",
    "    \n",
    "    # WORK ON THIS\n",
    "    # UPDATE XML FOR REFERENCE\n",
    "    # DiscreteMovements\n",
    "    cumulative_reward = racer.run(agent_host)\n",
    "    print('Cumulative reward: %d' % cumulative_reward)\n",
    "    cumulative_rewards += [ cumulative_reward ]\n",
    "    \n",
    "    racer.clear_actions()  # clear list of actions for next run\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "print(\"\\n\\nMission ended.\")\n",
    "print(\"Cumulative rewards for all %d runs:\" % num_reps)\n",
    "print(cumulative_rewards)\n",
    "# Mission has ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
