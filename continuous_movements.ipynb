{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "# import MalmoPython\n",
    "import malmo.MalmoPython as MalmoPython\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import errno\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, deque\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_q_table(q_table, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(q_table, f)\n",
    "\n",
    "def load_q_table(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        q_table = json.load(f)\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6, 3, -2, 6, 1, 32]\n",
      "[-4, -3, 30, 4, 15, 31]\n",
      "[-1, 0, 10, -1, 3, 10]\n",
      "[3, 0, 21, 3, 3, 21]\n",
      "[3, 0, 30, 3, 3, 30]\n",
      "[-1, 0, 22, -1, 3, 22]\n",
      "[2, 0, 10, 2, 3, 10]\n",
      "[1, 0, 3, 1, 3, 3]\n",
      "[1, 1, 25, 1, 1, 25]\n",
      "[2, 1, 22, -1, 1, 22]\n",
      "[-2, 1, 4, -3, 1, 4]\n",
      "[3, 1, 22, 1, 1, 22]\n",
      "[-1, 1, 18, -2, 1, 18]\n"
     ]
    }
   ],
   "source": [
    "random.seed()\n",
    "world_num = random.randint(0, 25)\n",
    "world_map = open('xmls/world_{world_num}.txt'.format(world_num = world_num), 'r')\n",
    "lines = world_map.readlines()\n",
    "logs = [] #tuple (block, (x,y,z))\n",
    "water = []\n",
    "diamond = []\n",
    "obs_set = set()\n",
    "\n",
    "def addObjects(line, block_name, obs_list):\n",
    "    terms = line.split()\n",
    "    coords = []\n",
    "\n",
    "    for i in range(1,7):\n",
    "        start = terms[i].index('\"') + 1\n",
    "        end = terms[i].index('\"', start)\n",
    "        coords.append(int(terms[i][start:end]))\n",
    "\n",
    "\n",
    "    if coords[0] < -6: #IF X is OUTSIDE OF OUR DESIRED RANGE -4, 4 we just dip.\n",
    "        return\n",
    "    if coords[2] > 30: #IF Z is outside. dip.\n",
    "        return\n",
    "    \n",
    "    if coords[0] == coords[3]:\n",
    "        x_range = [coords[0]]\n",
    "    else:\n",
    "        x_range = [x for x in range(min(coords[0],coords[3]), max(coords[0],coords[3])+ 1)] #do we need + 1 to make range inclusive?\n",
    "    \n",
    "    if coords[1] == coords[4]:\n",
    "        y_range = [coords[1]]\n",
    "    elif block_name == \"diamond_block\":\n",
    "        y_range = [1,2] # WE DON'T NEED TO ADD DIAMOND_BLOCKS THAT HIGHER THAN 6 IN Y-AXIS\n",
    "    elif coords[4] != coords[1]: #this was initially 4 1 swapped. not sure why?\n",
    "        y_range = [y for y in range(min(coords[1],coords[4]), max(coords[1],coords[4]))]\n",
    "    \n",
    "    if coords[2] == coords[5]:\n",
    "        z_range = [coords[2]]\n",
    "    else:\n",
    "        z_range = [z for z in range(coords[2], coords[5])] #this generally only happens for walls.\n",
    "    print(coords)\n",
    "\n",
    "    #this spawns way too many duplicates.\n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            for z in z_range:\n",
    "                obs_list.append((block_name, (x, y, z)))\n",
    "for line in lines:\n",
    "    if \"DrawCuboid\" in line:\n",
    "        if \"log\" in line:\n",
    "            addObjects(line, \"log\", logs)\n",
    "        if \"diamond_block\" in line:\n",
    "            addObjects(line, \"diamond_block\", diamond)\n",
    "    if \"DrawLine\" in line:\n",
    "        addObjects(line, \"water\", water)\n",
    "# print(logs)\n",
    "# print(diamond)\n",
    "# print(water)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ContinuousMovementCommands\n",
    "actions_space = ['move 1', 'strafe 1', 'strafe -1', 'jump 1']\n",
    "# REMINDER: VALUE OF EACH ACTION IS THE SPEED, NOT NUMBER OF TIMES\n",
    "# move  1    full speed ahead\n",
    "# move -1    full speed backwards\n",
    "# strafe 1   moves right at full speed\n",
    "# strafe -1  moves left at full speed\n",
    "# turn 1     turns full speed right\n",
    "# turn -1    turns full speed left\n",
    "# jump 1/0   starts/stops jumping\n",
    "\n",
    "\n",
    "INITIAL_LOCATION = (1, 2, 0)\n",
    "DIAMOND_WALL_Z = 30\n",
    "INITIAL_DISTANCE = DIAMOND_WALL_Z\n",
    "reward_map =  {\n",
    "            'diamond_block': 100,\n",
    "            'packed_ice': 1,\n",
    "            'log': -20,\n",
    "            'water': -2\n",
    "            }\n",
    "\n",
    "importantObjects = logs + diamond + water\n",
    "\n",
    "class Racer(object):\n",
    "    def __init__(self, alpha=0.3, gamma=1, n=5):\n",
    "        \"\"\"Constructing an RL agent.\n",
    "\n",
    "        Args\n",
    "            alpha:  <float>  learning rate      (default = 0.3)\n",
    "            gamma:  <float>  value decay rate   (default = 1)\n",
    "            n:      <int>    number of back steps to update (default = 5)\n",
    "        \"\"\"\n",
    "        self.epsilon = 0.3  # chance of taking a random action instead of the best\n",
    "        self.q_table = {}\n",
    "        self.n, self.alpha, self.gamma = n, alpha, gamma\n",
    "        self.actions_taken = []\n",
    "        self.num_actions = 0\n",
    "        self.reward = 0\n",
    "        self.diamond_reached = False\n",
    "        self.obstacles_hit = False\n",
    "        self.timer = time.time()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if False: # True if you want to see more information\n",
    "            self.logger.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "        self.logger.handlers = []\n",
    "        self.logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "        \n",
    "    def clear_actions(self):\n",
    "        \"\"\"Resets the actions in case of a new iteration to fetch. \"\"\"\n",
    "        self.actions_taken = []\n",
    "        self.num_actions = 0\n",
    "        self.reward = 0\n",
    "        self.diamond_reached = False\n",
    "        self.obstacles_hit = False\n",
    "        \n",
    "    def get_possible_actions(self, agent_host, term_flag):\n",
    "        \"\"\"Returns all possible actions that can be done at the current state. \"\"\"\n",
    "#         print(\"in get possible actions\")\n",
    "        action_list = []\n",
    "        if not term_flag:\n",
    "            action_list.extend(actions_space)\n",
    "        return action_list\n",
    "    \n",
    "    def choose_action(self, curr_state, possible_actions, eps):\n",
    "        \"\"\"Chooses an action according to eps-greedy policy. \"\"\"\n",
    "        if curr_state not in self.q_table:\n",
    "            self.q_table[curr_state] = {}\n",
    "        for action in possible_actions:\n",
    "            if action not in self.q_table[curr_state]:\n",
    "                self.q_table[curr_state][action] = 0\n",
    "        \n",
    "        rnd = random.random()\n",
    "        if rnd <= eps:\n",
    "            a = random.randint(0, len(possible_actions) - 1)\n",
    "            return possible_actions[a]\n",
    "        else:\n",
    "            # copy dict{actions: q-values} of q_table[curr_state]\n",
    "            state_actions =self.q_table[curr_state]\n",
    "            # find the max q-value\n",
    "            max_q = max(state_actions.values())\n",
    "            # find the list of actions that return the maximum q-value\n",
    "            max_actions = [action for action, value in state_actions.items() if value == max_q]\n",
    "            # pick a random action from the max_actions list\n",
    "            max_rand = random.randint(0, len(max_actions) - 1)\n",
    "            return max_actions[max_rand]\n",
    "        \n",
    "    def get_curr_location(self, agent_host):\n",
    "        # get the world state\n",
    "        world_state = agent_host.peekWorldState()\n",
    "        location = tuple()\n",
    "        if world_state.number_of_observations_since_last_state > 0:\n",
    "            msg = world_state.observations[-1].text\n",
    "            observations = json.loads(msg)\n",
    "            # get curr location from json\n",
    "            xpos = observations.get(u'XPos',0)\n",
    "            ypos = observations.get(u'YPos',0)\n",
    "            zpos = observations.get(u'ZPos',0)\n",
    "            location = (xpos, ypos, zpos)\n",
    "            #print(\"LOCATION: \", location)\n",
    "            return location\n",
    "        else:\n",
    "            return INITIAL_LOCATION\n",
    "        \n",
    "    def get_obj_locations(self, agent_host):\n",
    "        return logs + water + diamond\n",
    "    \n",
    "    def calculate_dist_reward(self, agent_host, currentState, timer):\n",
    "        #agent_z = self.get_curr_location(agent_host)[2]\n",
    "        agent_z = currentState[2]\n",
    "        dist_from_wall = DIAMOND_WALL_Z -agent_z\n",
    "        dist_traveled = INITIAL_DISTANCE - dist_from_wall\n",
    "#         print(\"traveled: \", dist_traveled)\n",
    "#         print(\"Dist From Wall: \", dist_from_wall)\n",
    "        reward = math.floor((dist_traveled*100)/INITIAL_DISTANCE)\n",
    "        if self.diamond_reached == True:\n",
    "            time_elapsed = time.time() - timer #find current runtime, minus time of starting.\n",
    "            reward += 200 // time_elapsed\n",
    "#             print(\"bonus reward: \", reward)\n",
    "        return reward\n",
    "    \n",
    "    def eval_current_state(self, agent_host, current_state, timer):\n",
    "#         print(\"current_state passed in eval:\", current_state)\n",
    "        #maybe need to set obstacles hit and diamond to false? but since its in a class shud be ok.\n",
    "        agent_loc = self.get_curr_location(agent_host)\n",
    "#         print(\"agent_loc =\", agent_loc)\n",
    "        nearby_objects = self.get_obj_locations(agent_host)\n",
    "        reward = self.calculate_dist_reward(agent_host, current_state, timer) \n",
    "        ######################################## MOVING THIS DOWN TO ACCOUNT FOR TIMER!!\n",
    "        for obj in nearby_objects:\n",
    "            obj_type, obj_loc = obj\n",
    "            obj_x, obj_y, obj_z = obj_loc\n",
    "\n",
    "            # Check for logs\n",
    "            if obj_type == 'log':\n",
    "#                 print(\"log loc =\", obj_loc)\n",
    "#                 print(\"agent loc =\", current_state)\n",
    "                if obj_z >= current_state[2] - 0.3 and obj_z <= current_state[2] + 0.3:\n",
    "#                     print(\"log loc =\", obj_loc)\n",
    "#                     print(\"agent loc =\", current_state)\n",
    "                    if obj_x >= current_state[0] - 0.1 and obj_x <= current_state[0] + 0.1:\n",
    "#                         print(\"log loc =\", obj_loc)\n",
    "#                         print(\"agent loc =\", current_state)\n",
    "                        #reward += reward_map['log']\n",
    "#                         print('we hit a log lol z and x: ', reward)\n",
    "                        self.obstacles_hit = True\n",
    "                        time.sleep(0.2) #adding this to pause the overdoing of collision reward dropping.\n",
    "                '''\n",
    "                The below condition seems problematic but the agent seems to be performing\n",
    "                very well with it for some reason. I have tried both current_state[1] -1 and current_state[1].\n",
    "                But it seems like the agent is most likely to hit the wall faster with current_state[1].\n",
    "                '''\n",
    "                if obj_y == current_state[1]:\n",
    "                # if obj_y == current_state[1] - 1:\n",
    "\n",
    "                    #reward += reward_map['log']\n",
    "                    #print('we hit a log lol y: ', reward)\n",
    "                    self.obstacles_hit = True\n",
    "\n",
    "            # Check for diamonds\n",
    "            elif obj_type == 'diamond_block' and obj_z >= current_state[2] and obj_z <= current_state[2] + 1:\n",
    "                #reward = reward_map['diamond_block'] #I feel like this should just be reward = \n",
    "                self.diamond_reached = True\n",
    "#                 print('we hit diamond!!')\n",
    "                time.sleep(0.2)\n",
    "            # Check for water\n",
    "            elif obj_type == 'water' and obj_z >= current_state[2] and obj_z <= current_state[2] + 1:\n",
    "                if obj_x >= current_state[0] - 1.5 and obj_x <= current_state[0] + 1.5:\n",
    "                    reward += reward_map['water']\n",
    "#                     print('puddle lol: ', self.reward)\n",
    "        \n",
    "        if self.obstacles_hit:\n",
    "            reward += reward_map['log']\n",
    "        if self.diamond_reached:\n",
    "            #Instead of commenting out reward, in the case of a diamond getting hit we will just reset it.\n",
    "            reward = self.calculate_dist_reward(agent_host, current_state, timer)\n",
    "            reward += reward_map['diamond_block']\n",
    "        return reward, self.diamond_reached, self.obstacles_hit\n",
    "    \n",
    "    def act(self, agent_host, action, timer): \n",
    "        #lowkey set up an action queue so we dont need\n",
    "        # to hardcode the jumpXmove action. if we have a while loop that just\n",
    "        #runs and constantly time.sleeps() per game state update, we would be able to jump/run\n",
    "        #without more problems. this should be fine for now. The code is just a little messier.\n",
    "#         print(action + \",\", end = \" \")\n",
    "        self.actions_taken.append(action)\n",
    "\n",
    "        term, size = action.split()\n",
    "        if term == 'jump': #pair it with move 1.\n",
    "            agent_host.sendCommand('move 1')\n",
    "            self.actions_taken.append('move 1')\n",
    "        term += ' 0'\n",
    "        \n",
    "        agent_host.sendCommand(action) #GO\n",
    "        time.sleep(0.4)\n",
    "        if term == 'jump 0': #pair it with move 1.\n",
    "            agent_host.sendCommand('move 0')\n",
    "            self.actions_taken.append('move 0')\n",
    "        agent_host.sendCommand(term)  #STOP\n",
    "        \n",
    "        # reevaluate the current state after action\n",
    "#         print('call current location in act')\n",
    "        curr_state = self.get_curr_location(agent_host)\n",
    "        if curr_state not in self.q_table:\n",
    "            self.q_table[curr_state] = {}\n",
    "        possible_actions = self.get_possible_actions(agent_host, False)\n",
    "        for action in possible_actions:\n",
    "            if action not in self.q_table[curr_state]:\n",
    "                self.q_table[curr_state][action] = 0                \n",
    "        \n",
    "        # high emphasis on this part since it greatly affects the flow of the entire mission\n",
    "        self.prev_s = curr_state\n",
    "        self.prev_a = action\n",
    "        \n",
    "        current_reward = self.eval_current_state(agent_host, curr_state, timer)[0]\n",
    "           \n",
    "        return current_reward, self.diamond_reached, self.obstacles_hit\n",
    "    \n",
    "    def update_q_table_without_tau(self, S, A, R, T):\n",
    "        \"\"\"Performs relevant updates for the Q-values.\n",
    "        TD(0) implementation of SARSA algorithm. Better for this use case.\n",
    "        Args\n",
    "            S:   <deque>   states queue\n",
    "            A:   <deque>   actions queue\n",
    "            R:   <deque>   rewards queue\n",
    "            T:   <int>      terminating state index\n",
    "\n",
    "        \"\"\"\n",
    "        G = 0\n",
    "#         print(\"R =\", R)\n",
    "#         print(\"S =\", S)\n",
    "#         print(\"A =\", A)\n",
    "        for i in range(len(S)-2, -1, -1):\n",
    "#             print(\"i =\", i)\n",
    "            G = self.gamma * G + R[i + 1]\n",
    "            old_q = self.q_table[S[i]][A[i]]\n",
    "            self.q_table[S[i]][A[i]] = old_q + self.alpha * (G - old_q)\n",
    "            \n",
    "    def updateQTableFromTerminatingState(self, reward):\n",
    "        \"\"\"Change q_table to reflect what we have learnt, after reaching a terminal state.\"\"\"\n",
    "        \n",
    "        # retrieve the old action value from the Q-table (indexed by the previous state and the previous action)\n",
    "        old_q = self.q_table[self.prev_s][self.prev_a]\n",
    "        \n",
    "        # TODO: what should the new action value be?\n",
    "        new_q = old_q\n",
    "        \n",
    "        # assign the new action value to the Q-table\n",
    "        self.q_table[self.prev_s][self.prev_a] = new_q\n",
    "        \n",
    "        \n",
    "    def run(self, agent_host, start_time): \n",
    "        \"\"\"Learns the process to reach the diamonds\"\"\"\n",
    "        S, A, R = deque(), deque(), deque()\n",
    "        total_reward = 0\n",
    "        present_reward = 0\n",
    "        done_update = False\n",
    "        self.prev_s = None\n",
    "        self.prev_a = None\n",
    "        \n",
    "        is_first_action = True\n",
    "    \n",
    "        world_state = agent_host.getWorldState()\n",
    "        while world_state.is_mission_running:\n",
    "            T = sys.maxsize\n",
    "            present_reward = 0\n",
    "            \n",
    "            if is_first_action:\n",
    "                # wait until we have received a valid observation\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    \n",
    "                    # scope for any errors that may occur in the world state\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                        \n",
    "                    # gather rewards for any found in world state\n",
    "                    for reward in world_state.rewards:\n",
    "                        present_reward += reward.getValue()\n",
    "                         \n",
    "                    # where the actual actions take place\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        term_flag = self.diamond_reached or self.obstacles_hit\n",
    "                        \n",
    "                        possible_actions = self.get_possible_actions(agent_host, term_flag)\n",
    "                        \n",
    "                        s0 = self.get_curr_location(agent_host)\n",
    "                        a0 = self.choose_action(s0, possible_actions, self.epsilon)\n",
    "                        \n",
    "                        S.append(s0)\n",
    "                        A.append(a0)\n",
    "                        R.append(0) # should we append returned_reward for a0 after self.act??\n",
    "                        \n",
    "#                         print(\"taking action: \", a0)\n",
    "                        # agent_host.sendCommand(a0);\n",
    "                        \n",
    "                        returned_reward, diamond_reached, obstacles_hit = self.act(agent_host, a0,start_time)\n",
    "                        time.sleep(0.2)\n",
    "#                         print(\"returned_reward: \", returned_reward)\n",
    "#                         print(\"diamond_reached: \", diamond_reached)\n",
    "#                         print(\"obstacles_hit?? \", obstacles_hit)\n",
    "#                         print(\"self.obstacles_hit =\", self.obstacles_hit)\n",
    "                        R.append(returned_reward)\n",
    "                        \n",
    "                        term_flag = self.diamond_reached or self.obstacles_hit\n",
    "#                         print(\"term flag =\", term_flag)\n",
    "                        \n",
    "                        total_reward += returned_reward\n",
    "                        # update Q values\n",
    "#                         print(\"S =\", S)\n",
    "#                         print(\"A =\", A)\n",
    "#                         print(\"R =\", R)\n",
    "                        if not term_flag and self.prev_s is not None and self.prev_a is not None:\n",
    "                            self.update_q_table_without_tau(S, A, R, T)\n",
    "                        \n",
    "                        # Terminating state\n",
    "                        # no need to go any further if we hit certain obstacle or goal\n",
    "                        # not using tau values for this implementation\n",
    "                        if term_flag:\n",
    "                            # we should be calculating reward if it hits a log.\n",
    "                            present_reward = returned_reward  # either = or +=\n",
    "#                             print(\"Reward:\", present_reward)\n",
    "                            \n",
    "#                             while len(S) > 1:\n",
    "#                                 self.update_q_table_without_tau(S, A, R, T)\n",
    "                            \n",
    "                            # process final reward\n",
    "                            self.logger.debug(\"Final reward: %d\" % present_reward)\n",
    "                            total_reward += present_reward\n",
    "\n",
    "                            # update Q values\n",
    "                            if self.prev_s is not None and self.prev_a is not None:\n",
    "#                                 self.updateQTableFromTerminatingState( present_reward )\n",
    "                                self.update_q_table_without_tau(S, A, R, T)\n",
    "\n",
    "                            return total_reward       \n",
    "                        else:\n",
    "                            s = self.get_curr_location(agent_host)\n",
    "                            S.append(s)\n",
    "                            possible_actions = self.get_possible_actions(agent_host, term_flag)\n",
    "                            next_a = self.choose_action(s, possible_actions, self.epsilon)\n",
    "                            A.append(next_a)\n",
    "                        \n",
    "                        break\n",
    "                    \n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "#                 print(\"first!!\")\n",
    "                is_first_action = False\n",
    "            else:\n",
    "                # wait for non-zero reward\n",
    "                ##############################################################\n",
    "#                 while world_state.is_mission_running and present_reward == 0:\n",
    "#                     time.sleep(0.1)\n",
    "#                     print(\"NO CAPPP\")\n",
    "#                     world_state = agent_host.getWorldState()\n",
    "                    \n",
    "#                     # scope for any errors that may occur in the world state\n",
    "#                     for error in world_state.errors:\n",
    "#                         self.logger.error(\"Error: %s\" % error.text)\n",
    "                        \n",
    "#                     # gather rewards for any found in world state\n",
    "#                     for reward in world_state.rewards:\n",
    "#                         present_reward += reward.getValue()\n",
    "                ##############################################################\n",
    "\n",
    "                # allow time to stabilise after action\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    \n",
    "                    # scope for any errors that may occur in the world state\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                        \n",
    "                    # gather rewards for any found in world state\n",
    "                    for reward in world_state.rewards:\n",
    "                        present_reward += reward.getValue()\n",
    "                    \n",
    "                    # where the actual actions take place\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        term_flag = self.diamond_reached or self.obstacles_hit\n",
    "                        \n",
    "                        s = self.get_curr_location(agent_host)\n",
    "                        S.append(s)\n",
    "                        possible_actions = self.get_possible_actions(agent_host, term_flag)\n",
    "                        next_a = self.choose_action(s, possible_actions, self.epsilon)\n",
    "                        A.append(next_a)\n",
    "                        \n",
    "#                         print(\"taking action: \", a0)\n",
    "                        # agent_host.sendCommand(a0);\n",
    "                        \n",
    "                        returned_reward, diamond_reached, obstacles_hit = self.act(agent_host, a0,start_time)\n",
    "                        time.sleep(0.2)\n",
    "#                         print(\"returned_reward: \", returned_reward)\n",
    "#                         print(\"diamond_reached: \", diamond_reached)\n",
    "#                         print(\"obstacles_hit?? \", obstacles_hit)\n",
    "                        \n",
    "                        term_flag = self.diamond_reached or self.obstacles_hit\n",
    "#                         print(\"term flag =\", term_flag)\n",
    "                        \n",
    "                        total_reward += returned_reward\n",
    "                        R.append(returned_reward)\n",
    "                        # update Q values\n",
    "                        if not term_flag and self.prev_s is not None and self.prev_a is not None:\n",
    "                            self.update_q_table_without_tau(S, A, R, T)\n",
    "                        \n",
    "                        # Terminating state\n",
    "                        # no need to go any further if we hit certain obstacle or goal\n",
    "                        # not using tau values for this implementation\n",
    "                        if term_flag:\n",
    "                            # we should be calculating reward if it hits a log.\n",
    "                            present_reward = returned_reward  # either = or +=\n",
    "#                             print(\"Reward:\", present_reward)\n",
    "                            \n",
    "#                             while len(S) > 1:\n",
    "#                                 self.update_q_table_without_tau(S, A, R, T)\n",
    "                            \n",
    "                            # process final reward\n",
    "                            self.logger.debug(\"Final reward: %d\" % present_reward)\n",
    "                            total_reward += present_reward\n",
    "\n",
    "                            # update Q values\n",
    "                            if self.prev_s is not None and self.prev_a is not None:\n",
    "#                                 self.updateQTableFromTerminatingState( present_reward \n",
    "                                self.update_q_table_without_tau(S, A, R, T)\n",
    "                            return total_reward       \n",
    "                        \n",
    "                        break\n",
    "                    \n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "    \n",
    "        # process final reward\n",
    "        self.logger.debug(\"Final reward: %d\" % present_reward)\n",
    "        total_reward += present_reward\n",
    "\n",
    "        # update Q values\n",
    "        if self.prev_s is not None and self.prev_a is not None:\n",
    "            self.updateQTableFromTerminatingState( present_reward )\n",
    "            \n",
    "#         print(\"diamond_reached: \", diamond_reached)\n",
    "                \n",
    "        return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "ERROR: Caught std::exception: unrecognised option '-f'\n",
      "\n",
      "Malmo version: 0.36.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n",
      "23\n",
      "Loading mission from xmls/world_23.txt\n",
      "n= 10\n",
      "epsilon= 0.3\n",
      "alpha= 0.3\n",
      "gamma= 1\n",
      "\n",
      "Waiting for the mission to start on trial 1\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 0.903296947479248 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 2\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 1.104252576828003 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 3\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 0.7029111385345459 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 4\n",
      "Mission running...\n",
      "Cumulative reward: -32\n",
      "--- 1.1057641506195068 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 5\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.702639102935791 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 6\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7022607326507568 seconds ---\n",
      "diamond reached?  False\n",
      "\n",
      "Waiting for the mission to start on trial 7\n",
      "Mission running...\n",
      "Cumulative reward: -32\n",
      "--- 1.1029534339904785 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 8\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7054340839385986 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 9\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7048225402832031 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 10\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7050976753234863 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 11\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7067146301269531 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 12\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7021758556365967 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 13\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7021734714508057 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 14\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7025086879730225 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 15\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7021932601928711 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 16\n",
      "Mission running...\n",
      "Cumulative reward: -24\n",
      "--- 0.7040107250213623 seconds ---\n",
      "diamond reached?  False\n",
      "\n",
      "Waiting for the mission to start on trial 17\n",
      "Mission running...\n",
      "Cumulative reward: -32\n",
      "--- 1.107008457183838 seconds ---\n",
      "diamond reached?  False\n",
      "\n",
      "Waiting for the mission to start on trial 18\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 0.7021629810333252 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 19\n",
      "Mission running...\n",
      "Cumulative reward: -32\n",
      "--- 0.7046675682067871 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 20\n",
      "Mission running...\n",
      "Cumulative reward: -22\n",
      "--- 0.7047977447509766 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 21\n",
      "Mission running...\n",
      "Cumulative reward: -12\n",
      "--- 1.103126049041748 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 22\n",
      "Mission running...\n",
      "Cumulative reward: -12\n",
      "--- 0.7022945880889893 seconds ---\n",
      "diamond reached?  False\n",
      "\n",
      "Waiting for the mission to start on trial 23\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 0.7075319290161133 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 24\n",
      "Mission running...\n",
      "Cumulative reward: -34\n",
      "--- 1.1039018630981445 seconds ---\n",
      "diamond reached?  False\n",
      "Error starting mission A mission is already running.\n",
      "Is the game running?\n",
      "\n",
      "Waiting for the mission to start on trial 25\n",
      "Mission running...\n",
      "Cumulative reward: 1283\n",
      "--- 16.975629568099976 seconds ---\n",
      "diamond reached?  True\n",
      "\n",
      "\n",
      "Mission ended.\n",
      "Cumulative rewards for all 25 runs:\n",
      "[-34, -34, -34, -32, -24, -24, -32, -24, -24, -24, -24, -24, -24, -24, -24, -24, -32, -34, -32, -22, -12, -12, -34, -34, 1283.0]\n",
      "\n",
      "Run times for all 25 runs in seconds:\n",
      "[0.903296947479248, 1.104252576828003, 0.7029111385345459, 1.1057641506195068, 0.702639102935791, 0.7022607326507568, 1.1029534339904785, 0.7054340839385986, 0.7048225402832031, 0.7050976753234863, 0.7067146301269531, 0.7021758556365967, 0.7021734714508057, 0.7025086879730225, 0.7021932601928711, 0.7040107250213623, 1.107008457183838, 0.7021629810333252, 0.7046675682067871, 0.7047977447509766, 1.103126049041748, 0.7022945880889893, 0.7075319290161133, 1.1039018630981445, 16.975629568099976]\n",
      "\n",
      "Agent had overall score of -34 on trial 1 with a run time of 0.9033 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -34 on trial 2 with a run time of 1.1043 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -34 on trial 3 with a run time of 0.7029 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -32 on trial 4 with a run time of 1.1058 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 5 with a run time of 0.7026 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 6 with a run time of 0.7023 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -32 on trial 7 with a run time of 1.1030 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 8 with a run time of 0.7054 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 9 with a run time of 0.7048 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 10 with a run time of 0.7051 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 11 with a run time of 0.7067 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 12 with a run time of 0.7022 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 13 with a run time of 0.7022 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 14 with a run time of 0.7025 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 15 with a run time of 0.7022 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -24 on trial 16 with a run time of 0.7040 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -32 on trial 17 with a run time of 1.1070 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -34 on trial 18 with a run time of 0.7022 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -32 on trial 19 with a run time of 0.7047 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -22 on trial 20 with a run time of 0.7048 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -12 on trial 21 with a run time of 1.1031 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -12 on trial 22 with a run time of 0.7023 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -34 on trial 23 with a run time of 0.7075 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of -34 on trial 24 with a run time of 1.1039 seconds. finished track? False \n",
      "\n",
      "Agent had overall score of 1283.0 on trial 25 with a run time of 16.9756 seconds. finished track? True \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)  # flush print output immediately\n",
    "    print('Starting...', flush=True)\n",
    "    q_table_save_frequency = 1  # save the Q-table after every 100 iterations\n",
    "    q_table_file = \"q_table.pckl\"\n",
    "    \n",
    "    my_client_pool = MalmoPython.ClientPool()\n",
    "    my_client_pool.add(MalmoPython.ClientInfo(\"127.0.0.1\", 10000))\n",
    "\n",
    "    agent_host = MalmoPython.AgentHost()\n",
    "    try:\n",
    "        agent_host.parse(sys.argv)\n",
    "    except RuntimeError as e:\n",
    "        print('ERROR:', e)\n",
    "        print(agent_host.getUsage())\n",
    "        exit(1)\n",
    "    if agent_host.receivedArgument(\"help\"):\n",
    "        print(agent_host.getUsage())\n",
    "        exit(0)\n",
    "    \n",
    "    print(world_num)  # defined above when finding obstacle coords\n",
    "    mission_file = 'xmls/world_{world_num}.txt'.format(world_num = world_num)\n",
    "\n",
    "    with open(mission_file, 'r') as f:\n",
    "        print(\"Loading mission from %s\" % mission_file)\n",
    "        missionXML = f.read()\n",
    "\n",
    "    \n",
    "    num_reps = 25\n",
    "    n=10\n",
    "    run_times = []\n",
    "    finished_track = []\n",
    "    actions_taken = []\n",
    "    \n",
    "    racer = Racer(n=n)\n",
    "    \n",
    "    '''\n",
    "    alpha:  <float>  learning rate      (default = 0.3)\n",
    "    gamma:  <float>  value decay rate   (default = 1)\n",
    "    n:      <int>    number of back steps to update   (default = 5)\n",
    "    epsilon <int>    chance of taking a random action instead of the best   (default = 0.3)\n",
    "    '''\n",
    "    racer.epsilon = 0.3  # for testing purposes\n",
    "    racer.alpha = 0.3\n",
    "    racer.gamma = 1\n",
    "    racer.n = n\n",
    "    \n",
    "    print(\"n=\", racer.n)\n",
    "    print(\"epsilon=\", racer.epsilon)\n",
    "    print(\"alpha=\", racer.alpha)\n",
    "    print(\"gamma=\", racer.gamma)        \n",
    "        \n",
    "    racer.clear_actions()\n",
    "    \n",
    "    cumulative_rewards = []\n",
    "    for iRepeat in range(num_reps):\n",
    "        my_mission = MalmoPython.MissionSpec(missionXML, True)\n",
    "        my_mission_record = MalmoPython.MissionRecordSpec()  # Records nothing by default\n",
    "        my_mission.requestVideo(1260, 960)\n",
    "        my_mission.setViewpoint(0)\n",
    "        \n",
    "        # attempt to start a mission\n",
    "        max_retries = 3\n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                agent_host.startMission( my_mission, my_client_pool, my_mission_record, 0, \"Racer\")\n",
    "                break\n",
    "            except RuntimeError as e:\n",
    "                if retry == max_retries - 1:\n",
    "                    print(\"Error starting mission\", e)\n",
    "                    print(\"Is the game running?\")\n",
    "                    exit(1)\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "\n",
    "        # Loop until mission starts:\n",
    "        print(\"\\nWaiting for the mission to start on trial\", iRepeat+1)\n",
    "        world_state = agent_host.getWorldState()\n",
    "        \n",
    "        while not world_state.has_mission_begun:\n",
    "            time.sleep(0.1)\n",
    "            world_state = agent_host.getWorldState()\n",
    "            \n",
    "            for error in world_state.errors:\n",
    "                print(\"Error:\",error.text) \n",
    "                \n",
    "        print(\"Mission running...\")\n",
    "        \n",
    "        # log time for each run\n",
    "        start_time = time.time()\n",
    "        \n",
    "        cumulative_reward = racer.run(agent_host, start_time)\n",
    "        print('Cumulative reward: %d' % cumulative_reward)\n",
    "        cumulative_rewards += [ cumulative_reward ]\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(\"--- %s seconds ---\" % (time_elapsed))\n",
    "        run_times.append(time_elapsed)\n",
    "        \n",
    "        print(\"diamond reached? \", racer.diamond_reached)\n",
    "        finished_track.append(racer.diamond_reached)\n",
    "        \n",
    "        \n",
    "#         with open('q_table.pckl', 'wb') as f:\n",
    "#             pickle.dump(racer.q_table, f)\n",
    "#         print('Q-table saved.')\n",
    "#         with open('q_table.pkl', 'rb') as read_q:\n",
    "#             q_table = pickle.load(read_q)\n",
    "#             print(q_table)\n",
    "\n",
    "#         print(racer.actions_taken)\n",
    "        actions_taken.append(racer.actions_taken)\n",
    "    \n",
    "        racer.clear_actions()\n",
    "        time.sleep(1)\n",
    "        \n",
    "\n",
    "print(\"\\n\\nMission ended.\")\n",
    "print(\"Cumulative rewards for all %d runs:\" % num_reps)\n",
    "print(cumulative_rewards)\n",
    "\n",
    "print(\"\\nRun times for all %d runs in seconds:\" % num_reps)\n",
    "print(run_times)\n",
    "\n",
    "for i in range(0, num_reps):\n",
    "    print(\"\\nAgent had overall score of %s on trial %s with a run time of %.4f seconds. finished track? %s \" % (cumulative_rewards[i], i+1, run_times[i], finished_track[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting time elapsed per run (sec)...\n",
      "n= 10\n",
      "epsilon= 0.3\n",
      "alpha= 0.3\n",
      "gamma= 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe40e9ab7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plotting time elapsed per run (sec)...\")\n",
    "print(\"n=\", racer.n)\n",
    "print(\"epsilon=\", racer.epsilon)\n",
    "print(\"alpha=\", racer.alpha)\n",
    "print(\"gamma=\", racer.gamma) \n",
    "\n",
    "x = []\n",
    "for i in range(num_reps):\n",
    "    x.append(i)\n",
    "\n",
    "plt.figure(figsize=(num_reps//2, 8));\n",
    "plt.xticks(x);\n",
    "plt.title(\"Time elapsed per run (sec)\")\n",
    "plt.plot(x, run_times)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting total reward per run...\n",
      "n= 10\n",
      "epsilon= 0.3\n",
      "alpha= 0.3\n",
      "gamma= 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe40c101b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plotting total reward per run...\")\n",
    "print(\"n=\", racer.n)\n",
    "print(\"epsilon=\", racer.epsilon)\n",
    "print(\"alpha=\", racer.alpha)\n",
    "print(\"gamma=\", racer.gamma)  \n",
    "\n",
    "x = []\n",
    "for i in range(num_reps):\n",
    "    x.append(i)\n",
    "\n",
    "plt.figure(figsize=(num_reps//2, 8));\n",
    "plt.xticks(x);\n",
    "plt.title(\"Total reward per run\")\n",
    "plt.plot(x, cumulative_rewards, 'ro')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting number of actions taken per run...\n",
      "n= 10\n",
      "epsilon= 0.3\n",
      "alpha= 0.3\n",
      "gamma= 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3fffc2cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plotting number of actions taken per run...\")\n",
    "print(\"n=\", racer.n)\n",
    "print(\"epsilon=\", racer.epsilon)\n",
    "print(\"alpha=\", racer.alpha)\n",
    "print(\"gamma=\", racer.gamma)  \n",
    "\n",
    "x = []\n",
    "for i in range(num_reps):\n",
    "    x.append(i)\n",
    "    \n",
    "y = []\n",
    "for i in range(len(actions_taken)):\n",
    "    y.append(len(actions_taken[i]))\n",
    "\n",
    "plt.figure(figsize=(num_reps//2, 8));\n",
    "plt.xticks(x)\n",
    "plt.title(\"Number of actions taken per run\")\n",
    "plt.plot(x, y, 'go')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
